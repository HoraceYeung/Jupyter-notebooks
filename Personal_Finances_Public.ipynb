{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Understanding my finances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Purpose\n",
    "The purpose of this notebook is to expose some insights around my finances and where my money goes (expenditures).\n",
    "\n",
    "We will consider two sources of data for this analysis: my chequing account statement and my credit card statement."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Context and Scope\n",
    "To inform interpretation of the data, some context and scope:  \n",
    "  \n",
    "- Salary is paid into the chequing account\n",
    "- Chequing account transactions will include transfers between other accounts. These transactions should be excluded from this analysis, as our purpose is to understand my expenditures\n",
    "- Credit card transactions will include payments of the balance, recorded as credits. These will be excluded from this analysis as they do not provide additional insight into my finances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up external imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import datetime\n",
    "import calendar\n",
    "from scipy.stats import shapiro\n",
    "import statsmodels.api as sm\n",
    "idx = pd.IndexSlice\n",
    "\n",
    "print(\"External modules imported\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define file path\n",
    "fpath = \"./Personal_Finances/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions used in this notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to save plots to .png files\n",
    "def generate_png(name):\n",
    "    pltfile = fpath + name\n",
    "    plt.savefig(pltfile, dpi=300, format=\"png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to add a transaction type field\n",
    "def add_transaction_type(col):\n",
    "    if col < 0:\n",
    "        return \"D\"\n",
    "    else:\n",
    "        return \"C\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"Set up complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. First, let us load the transaction data and do some basic formatting\n",
    "__Raw data__:  \n",
    "\n",
    "cheque_data  \n",
    "credit_data  \n",
    "\n",
    "__Formatted data__:  \n",
    "\n",
    "tran_cheque_data  \n",
    "tran_credit_data  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find files\n",
    "import os\n",
    "\n",
    "for root, dirs, files in os.walk(fpath):\n",
    "    for file in files:\n",
    "        print(os.path.join(root, file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load chequing account transactions\n",
    "cheque_data = pd.read_csv('.\\Personal_Finances\\chq.csv', skiprows=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cheque_data.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get chequing data dtypes\n",
    "cheque_data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Format chequing data types\n",
    "tran_cheque_data = cheque_data.drop([\"Cheque Number\",\"Date\"], axis=1)\n",
    "tran_cheque_data[\"TransactionDate\"] = pd.to_datetime(cheque_data[\"Date\"], format=\"%Y/%m/%d\")\n",
    "tran_cheque_data[\"Type\"] = cheque_data[\"Amount\"].apply(add_transaction_type)\n",
    "tran_cheque_data[\"Amount\"] = cheque_data[\"Amount\"].apply(lambda x: abs(x))\n",
    "tran_cheque_data[\"Raw Amount\"] = cheque_data[\"Amount\"]\n",
    "# tran_cheque_data[\"Year\"] = tran_cheque_data[\"TransactionDate\"].dt.year\n",
    "tran_cheque_data[\"Details\"] = cheque_data[[\"Payee\",\"Memo\"]].fillna(value='').astype(str).agg(\" \".join, axis=1)\n",
    "tran_cheque_data = tran_cheque_data.assign(Account=\"CHQ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check formatted data\n",
    "tran_cheque_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load credit card transactions\n",
    "credit_data = pd.read_csv('.\\Personal_Finances\\crd.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "credit_data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "credit_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tran_credit_data = credit_data.drop([\"Card\"], axis=1)\n",
    "tran_credit_data[\"TransactionDate\"] = pd.to_datetime(credit_data[\"TransactionDate\"], format=\"%d/%m/%Y\")\n",
    "tran_credit_data[\"ProcessedDate\"] = pd.to_datetime(credit_data[\"ProcessedDate\"], format=\"%d/%m/%Y\")\n",
    "tran_credit_data[\"ForeignTransaction\"] = tran_credit_data[\"ForeignCurrencyAmount\"].notnull()\n",
    "# tran_credit_data[\"Year\"] = tran_credit_data[\"TransactionDate\"].dt.year\n",
    "tran_credit_data = tran_credit_data.assign(Account=\"CRD\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check formatted data\n",
    "tran_credit_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Next, we will separate the transactions into credits and debits for each group.\n",
    "We can expect the following broad groups of transactions:\n",
    "\n",
    "For the chequing transactions:\n",
    "  \n",
    "Credits:\n",
    "- Salary\n",
    "- General credits\n",
    "  \n",
    "Debits:\n",
    "- Transfers to other bank account (where we have the credit card)\n",
    "- General debits\n",
    "\n",
    "For the credit card transactions:\n",
    "  \n",
    "Credits:\n",
    "- Paying off card balance\n",
    "- Refunds\n",
    "  \n",
    "Debits:\n",
    "- General transactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chequing data sets\n",
    "chq_d = tran_cheque_data[tran_cheque_data[\"Type\"] == \"D\"]\n",
    "chq_c = tran_cheque_data[tran_cheque_data[\"Type\"] == \"C\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Chequing data count:\", len(tran_cheque_data.index))\n",
    "print(\"Chequing debits count:\", len(chq_d.index))\n",
    "print(\"Chequing credits count:\", len(chq_c.index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Credit card data sets\n",
    "crd_d = tran_credit_data[tran_credit_data[\"Type\"] == \"D\"]\n",
    "crd_c = tran_credit_data[tran_credit_data[\"Type\"] == \"C\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Credit Card data shape:\", len(tran_credit_data.index))\n",
    "print(\"Credit Card debits shape:\", len(crd_d.index))\n",
    "print(\"Credit Card credits shape:\", len(crd_c.index))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. We want a unique set of debits and credits\n",
    "We will now transform the data according to the scope highlighted at the start of this notebook.\n",
    "\n",
    "We want to join the chequing and credit card debit sets to get a view of where our money is going, without duplicates.\n",
    "We want to also join the chequing and credit card credits, while separating credit card payments.\n",
    "\n",
    "We will separate transactions out of scope and store them in separate sets.\n",
    "\n",
    "Finally, we want to apply the same format to the credit and debit data sets and append where appropriate for these sets:\n",
    "  \n",
    "1. Unique set of debits showing cash flow out of our accounts\n",
    "2. Unique set of credits showing cash flow into our accounts\n",
    "3. Credit card payments\n",
    "4. Out of scope transactions for our accounts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's have a look at the chequing account transactions to see if we can find some way to separate out of scope transactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Identify what the Tran Type field corresponds to\n",
    "\n",
    "# chq_d_cnt = chq_d.groupby([\"Tran Type\", \"Year\"]).size().sort_values(ascending=False)\n",
    "chq_d_cnt = chq_d.groupby([\"Tran Type\"]).size().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformation rules to filter out of scope data\n",
    "# Remove savings and investment transactions\n",
    "chq_d_flt = # details omitted\n",
    "len(chq_d_flt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chq_d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Get amount values by type\n",
    "# chq_d_sum = chq_d.groupby([\"Tran Type\", \"Year\"])[\"Amount\"].sum().sort_values(ascending=False)\n",
    "chq_d_sum = chq_d.groupby([\"Tran Type\"])[\"Amount\"].sum().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Get summarised values\n",
    "chq_d_sv = pd.DataFrame(chq_d_cnt).join(pd.DataFrame(chq_d_sum))\n",
    "chq_d_sv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chq_c_cnt = chq_c.groupby([\"Tran Type\", \"Year\"]).size().sort_values(ascending=False)\n",
    "chq_c_cnt = chq_c.groupby([\"Tran Type\"]).size().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Get amount values by type\n",
    "# chq_c_sum = chq_c.groupby([\"Tran Type\", \"Year\"])[\"Amount\"].sum().sort_values(ascending=False)\n",
    "chq_c_sum = chq_c.groupby([\"Tran Type\"])[\"Amount\"].sum().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Get summarised values\n",
    "chq_c_sv = pd.DataFrame(chq_c_cnt).join(pd.DataFrame(chq_c_sum))\n",
    "chq_c_sv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### All credit card credit transactions are essentially in scope. We need to check if debit transactions will need to be filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visual inspection of credit transactions \n",
    "crd_c.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crd_d.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### There are a few refund transactions. Nothing is available to filter these on, may affect our stats slightly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's get our common set of debits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Verify columns and get common set for debits\n",
    "# crd_d.columns\n",
    "# chq_d.columns\n",
    "\n",
    "# cols = ['TransactionDate', 'Year', 'Account', 'Type', 'Details', 'Amount']\n",
    "cols = ['TransactionDate', 'Account', 'Type', 'Details', 'Amount']\n",
    "combined_d = crd_d[cols].append(chq_d_flt[cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's look at the 10 top transactions by Amount\n",
    "combined_d.sort_values(by=\"Amount\", ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Aggregate visualisations on combined debit set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weekly aggregate view"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tmp = combined_d.join(combined_d[\"TransactionDate\"].dt.isocalendar().set_index(combined_d[\"TransactionDate\"]).drop_duplicates(), on=\"TransactionDate\").drop(\"day\", axis=1).groupby([\"Account\", \"year\", \"week\"]).sum().unstack([1,0]) \n",
    "# tmp.columns = tmp.columns.droplevel(0)\n",
    "# tmp = tmp.sort_index(axis=1)\n",
    "# # tmp.columns = tmp.columns\n",
    "# tmp == combined_d_week_by_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. aggregate our combined transactions to get the sums per week\n",
    "combined_d_week = combined_d.groupby([\"Account\"]).resample(\"W\", on=\"TransactionDate\").sum()\n",
    "combined_d_week.reset_index(0, inplace=True)\n",
    "# 2. get week number and group by account, week to get our summarised stats\n",
    "combined_d_week_by_acc = combined_d_week.join(combined_d_week.index.isocalendar().drop_duplicates()).pivot(index=\"week\", columns=[\"year\",\"Account\"], values=\"Amount\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_d_week_total = combined_d_week_by_acc.groupby(\"year\", axis=1).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "week_2020 = combined_d_week_by_acc.loc[:,idx[2020]]\n",
    "\n",
    "for i in range(week_2020.shape[1]):\n",
    "    plt.plot(week_2020.iloc[:,i], label = week_2020.columns[i])\n",
    "    \n",
    "plt.xlabel(\"Week of Year\")\n",
    "plt.ylabel(\"Amount $NZD\")\n",
    "plt.title(\"Spend vs Week of Year 2020\")\n",
    "plt.legend()\n",
    "plt.tick_params(axis='y',\n",
    "                which='both',\n",
    "                left=False,\n",
    "                labelleft=False)\n",
    "# Adjust plot spacing\n",
    "size = plt.gcf().get_size_inches()\n",
    "size[0] *= 1.4\n",
    "plt.gcf().set_size_inches(size)\n",
    "# plt.ylim(top=n)\n",
    "\n",
    "generate_png(\"spend_vs_week_of_year_2020.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "week_2019 = combined_d_week_by_acc.loc[:,idx[2019]]\n",
    "\n",
    "for i in range(week_2019.shape[1]):\n",
    "    plt.plot(week_2019.iloc[:,i], label = week_2019.columns[i])\n",
    "\n",
    "plt.xlabel(\"Week of Year\")\n",
    "plt.ylabel(\"Amount $NZD\")\n",
    "plt.title(\"Spend vs Week of Year 2019\")\n",
    "plt.legend()\n",
    "plt.tick_params(axis='y',\n",
    "                which='both',\n",
    "                left=False,\n",
    "                labelleft=False)\n",
    "# Adjust plot spacing\n",
    "size = plt.gcf().get_size_inches()\n",
    "size[0] *= 1.4\n",
    "plt.gcf().set_size_inches(size)\n",
    "# plt.ylim(top=n)\n",
    "\n",
    "generate_png(\"spend_vs_week_of_year_2019.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in range(combined_d_week_total.shape[1]):\n",
    "    plt.plot(combined_d_week_total.iloc[:,i], label = combined_d_week_total.columns[i])\n",
    "    \n",
    "expected = pd.Series(n, index=week_2019.index)\n",
    "plt.plot(expected, label='expected')\n",
    "\n",
    "combined_d_week_total.mean()\n",
    "\n",
    "for i in range(len(combined_d_week_total.mean())):\n",
    "    plt.plot(pd.Series(combined_d_week_total.mean().iloc[i], index=combined_d_week_total.index), label = 'mean ' + str(combined_d_week_total.mean().index[i]))\n",
    "\n",
    "# mean = pd.Series(combined_d_week_total.mean(), index=week_2019.index)\n",
    "# plt.plot(mean, label='mean')\n",
    "\n",
    "plt.xlabel(\"Week of Year\")\n",
    "plt.ylabel(\"Amount $NZD\")\n",
    "plt.title(\"Spend vs Week of Year\")\n",
    "plt.legend()\n",
    "plt.tick_params(axis='y',\n",
    "                which='both',\n",
    "                left=False,\n",
    "                labelleft=False)\n",
    "# Adjust plot spacing\n",
    "size = plt.gcf().get_size_inches()\n",
    "size[0] *= 1.4\n",
    "plt.gcf().set_size_inches(size)\n",
    "# plt.ylim(top=n)\n",
    "\n",
    "generate_png(\"spend_vs_week_of_year.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Day of week aggregate view"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate by day-of-week/account\n",
    "# 1. aggregate our combined transactions to get the sums per date\n",
    "combined_d_dow_by_acc = combined_d.groupby([\"Account\",\"TransactionDate\"]).sum()\n",
    "# 2. get our day of week\n",
    "combined_d_dow_by_acc = combined_d_dow_by_acc.reset_index(0).join(pd.date_range('2019-01-01','2020-12-31').isocalendar(), on=\"TransactionDate\").drop([\"week\",\"year\"], axis=1)\n",
    "# 3. group by account, day-of-week and get our summarised stats\n",
    "combined_d_dow_by_acc = combined_d_dow_by_acc.groupby([\"Account\",\"day\"]).agg([np.sum, np.mean, np.median, np.size]).unstack(0)\n",
    "# 4. get day-of-week names\n",
    "combined_d_dow_by_acc.set_index(combined_d_dow_by_acc.reset_index()[\"day\"].apply(lambda x: calendar.day_name[x-1]), inplace=True)\n",
    "# 5. remove column multi-index level\n",
    "combined_d_dow_by_acc.columns = combined_d_dow_by_acc.columns.droplevel(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate by day-of-week\n",
    "# 1. aggregate our combined transactions to get the sums per date\n",
    "combined_d_dow_total = combined_d.groupby([\"TransactionDate\"]).sum()\n",
    "# 2. get our day of week\n",
    "combined_d_dow_total = combined_d_dow_total.reset_index(0).join(pd.date_range('2019-01-01','2020-12-31').isocalendar(), on=\"TransactionDate\").drop([\"week\",\"year\"], axis=1)\n",
    "# 3. group by day-of-week and get our summarised stats\n",
    "combined_d_dow_total = combined_d_dow_total.groupby([\"day\"]).agg([np.sum, np.mean, np.median, np.size])\n",
    "# 4. get day-of-week names\n",
    "combined_d_dow_total.set_index(combined_d_dow_total.reset_index()[\"day\"].apply(lambda x: calendar.day_name[x-1]), inplace=True)\n",
    "# 5. remove column multi-index level\n",
    "combined_d_dow_total.columns = combined_d_dow_total.columns.droplevel(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_d_dow_by_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_d_dow_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_data = combined_d_dow_by_acc.loc[:,idx['mean']]\n",
    "for i in range(mean_data.shape[1]):\n",
    "    plt.plot(mean_data.iloc[:,i], label = mean_data.columns[i])\n",
    "    \n",
    "expected = pd.Series(n, index=mean_data.index)\n",
    "plt.plot(expected, label='expected')\n",
    "\n",
    "plt.plot('mean', data=combined_d_dow_total, label='combined')\n",
    "plt.xlabel(\"Day of Week\")\n",
    "plt.ylabel(\"Amount $NZD\")\n",
    "plt.title(\"Mean Spend vs Day of Week\")\n",
    "plt.legend()\n",
    "plt.tick_params(axis='y',\n",
    "                which='both',\n",
    "                left=False,\n",
    "                labelleft=False)\n",
    "# Adjust plot spacing\n",
    "size = plt.gcf().get_size_inches()\n",
    "size[0] *= 1.4\n",
    "plt.gcf().set_size_inches(size)\n",
    "# print(combined_d_dow_by_acc.loc[:,idx[['mean','size'], :]])\n",
    "# print(combined_d_dow_total.loc[:,['mean','size']])\n",
    "\n",
    "generate_png(\"mean_spend_vs_day_of_week.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "median_data = combined_d_dow_by_acc.loc[:,idx['median']]\n",
    "for i in range(median_data.shape[1]):\n",
    "    plt.plot(median_data.iloc[:,i], label = median_data.columns[i])\n",
    "    \n",
    "expected = pd.Series(n, index=median_data.index)\n",
    "plt.plot(expected, label='expected')\n",
    "    \n",
    "# plt.plot('mean', data=combined_d_dow_by_acc.loc[:,idx[:, 'CHQ']], label='CHQ')\n",
    "# plt.plot('mean', data=combined_d_dow_by_acc.loc[:,idx[:, 'CRD']], label='CRD')\n",
    "plt.plot('median', data=combined_d_dow_total, label='Combined')\n",
    "plt.xlabel(\"Day of Week\")\n",
    "plt.ylabel(\"Amount $NZD\")\n",
    "plt.title(\"Median Spend vs Day of Week\")\n",
    "plt.legend()\n",
    "plt.tick_params(axis='y',\n",
    "                which='both',\n",
    "                left=False,\n",
    "                labelleft=False)\n",
    "# Adjust plot spacing\n",
    "size = plt.gcf().get_size_inches()\n",
    "size[0] *= 1.4\n",
    "plt.gcf().set_size_inches(size)\n",
    "# print(combined_d_dow_by_acc.loc[:,idx[['mean','size'], :]])\n",
    "# print(combined_d_dow_total.loc[:,['mean','size']])\n",
    "\n",
    "generate_png(\"median_spend_vs_day_of_week.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transaction count by Account, day-of-week\n",
    "# 1. get our day of week\n",
    "combined_d_dow_count_by_acc = combined_d.join(pd.date_range('2019-01-01','2020-12-31').isocalendar(), on=\"TransactionDate\").drop([\"week\",\"year\"], axis=1)\n",
    "# 2. group by account, day-of-week and get our count\n",
    "combined_d_dow_count_by_acc = combined_d_dow_count_by_acc.groupby([\"Account\",\"day\"]).size().unstack(0)\n",
    "# 3. get day-of-week names\n",
    "combined_d_dow_count_by_acc.set_index(combined_d_dow_count_by_acc.reset_index()[\"day\"].apply(lambda x: calendar.day_name[x-1]), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transaction count by day-of-week\n",
    "# 1. get our day of week\n",
    "combined_d_dow_count_total = combined_d.join(pd.date_range('2019-01-01','2020-12-31').isocalendar(), on=\"TransactionDate\").drop([\"week\",\"year\"], axis=1)\n",
    "# 2. group by day-of-week and get our count\n",
    "combined_d_dow_count_total = pd.DataFrame(combined_d_dow_count_total.groupby([\"day\"]).size().rename(\"count\"))\n",
    "# 3. get day-of-week names\n",
    "combined_d_dow_count_total.set_index(combined_d_dow_count_total.reset_index()[\"day\"].apply(lambda x: calendar.day_name[x-1]), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "size_data = combined_d_dow_count_by_acc\n",
    "for i in range(size_data.shape[1]):\n",
    "    plt.plot(size_data.iloc[:,i], label = size_data.columns[i])\n",
    "    \n",
    "plt.plot('count', data=combined_d_dow_count_total, label='Combined')\n",
    "\n",
    "plt.xlabel(\"Day of Week\")\n",
    "plt.ylabel(\"Transaction Count\")\n",
    "plt.title(\"Number of Transactions vs Day of Week\")\n",
    "plt.legend()\n",
    "plt.tick_params(axis='y',\n",
    "                which='both',\n",
    "                left=False,\n",
    "                labelleft=False)\n",
    "# Adjust plot spacing\n",
    "size = plt.gcf().get_size_inches()\n",
    "size[0] *= 1.4\n",
    "plt.gcf().set_size_inches(size)\n",
    "# print(combined_d_dow_by_acc.loc[:,idx[['mean','size'], :]])\n",
    "# print(combined_d_dow_total.loc[:,['mean','size']])\n",
    "\n",
    "generate_png(\"transactions_vs_day_of_week.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Weekly spend distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_d_week_total.unstack().max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_d_week_total_all = combined_d_week_total.unstack()\n",
    "\n",
    "n, bins, patches = plt.hist(x=combined_d_week_total_all,\n",
    "                            bins='auto',\n",
    "                            alpha=0.7, \n",
    "                            rwidth=0.85)\n",
    "plt.xlabel('Amount ($NZD)')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Amount of Weekly Spend (n=106)')\n",
    "plt.tick_params(axis='x',\n",
    "                which='both',\n",
    "                bottom=False,\n",
    "                labelbottom=False)\n",
    "\n",
    "generate_png(\"amount_of_weekly_spend.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "shapiro(combined_d_week_total_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm.qqplot(combined_d_week_total_all, line ='45')\n",
    "plt.tick_params(axis='both',\n",
    "                which='both',\n",
    "                bottom=False,\n",
    "                labelbottom=False,\n",
    "                left=False,\n",
    "                labelleft=False)\n",
    "\n",
    "generate_png(\"amount_of_weekly_spend_qqplot.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n, bins, patches = plt.hist(x=combined_d_week_total, \n",
    "                            bins='auto',\n",
    "                            label=combined_d_week_total.columns,\n",
    "                            alpha=0.7, \n",
    "                            rwidth=0.85)\n",
    "plt.xlabel('Amount ($NZD)')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Amount of Weekly Spend by year (n=106)')\n",
    "plt.legend()\n",
    "plt.tick_params(axis='x',\n",
    "                which='both',\n",
    "                bottom=False,\n",
    "                labelbottom=False)\n",
    "\n",
    "generate_png(\"amount_of_weekly_spend_by_year.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "shapiro(combined_d_week_total[2020])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shapiro(combined_d_week_total[2019])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm.qqplot(combined_d_week_total[2020], line ='45')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm.qqplot(combined_d_week_total[2019], line ='45')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Daily spend distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_d_daily = combined_d.resample('D', on=\"TransactionDate\").sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n, bins, patches = plt.hist(x=combined_d_daily, \n",
    "                            bins=bins,\n",
    "                            label=combined_d_daily.columns,\n",
    "                            alpha=0.7, \n",
    "                            rwidth=0.85)\n",
    "plt.xlabel('Amount ($NZD)')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Amount of Daily Spend (n=731)')\n",
    "plt.tick_params(axis='x',\n",
    "                which='both',\n",
    "                bottom=False,\n",
    "                labelbottom=False)\n",
    "\n",
    "generate_png(\"amount_of_daily_spend.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n, bins, patches = plt.hist(x=combined_d_daily, \n",
    "                            bins='auto',\n",
    "                            label=combined_d_daily.columns,\n",
    "                            alpha=0.7, \n",
    "                            rwidth=0.85)\n",
    "plt.xlabel('Amount ($NZD)')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Amount of Daily Spend (n=731)')\n",
    "plt.tick_params(axis='x',\n",
    "                which='both',\n",
    "                bottom=False,\n",
    "                labelbottom=False)\n",
    "\n",
    "generate_png(\"amount_of_daily_spend_full.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm.qqplot(combined_d_daily, line ='45')\n",
    "plt.tick_params(axis='both',\n",
    "                which='both',\n",
    "                bottom=False,\n",
    "                labelbottom=False,\n",
    "                left=False,\n",
    "                labelleft=False)\n",
    "\n",
    "generate_png(\"amount_of_daily_spend_qqplot.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_d_daily.plot(kind='box')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_d.groupby('Account')[\"Amount\"].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_d[combined_d[\"Account\"]==\"CHQ\"].sort_values(by=\"Amount\", ascending=False).head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
